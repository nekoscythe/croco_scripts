#!/bin/bash

# Ensure the script is run from the test directory
TEST_DIR="$(pwd)"
METADATA_FILE="$TEST_DIR/metadata.yaml"
LOG_FILE="$TEST_DIR/outputs/run_test.log"
ARCHIVE_DIR="$TEST_DIR/outputs/archive"

# Check if metadata.yaml exists
if [[ ! -f "$METADATA_FILE" ]]; then
    echo "Error: metadata.yaml not found in $TEST_DIR."
    exit 1
fi

# Create necessary directories
mkdir -p "$TEST_DIR/outputs"
mkdir -p "$ARCHIVE_DIR"

# renew the log file in case it already exists
if [[ -f "$LOG_FILE" ]]; then
    rm "$LOG_FILE"
fi
# Redirect output to the log file
exec > >(tee "$LOG_FILE") 2>&1

# Read test details from metadata.yaml
TEST_NAME=$(yq eval '.test_name' "$METADATA_FILE")
TEST_ID=$(yq eval '.test_id' "$METADATA_FILE")
TEST_REASON=$(yq eval '.reason' "$METADATA_FILE")
BINARY_PATH=$(yq eval '.binary_path' "$METADATA_FILE")

# Convert paths to relative format
REL_INPUT_FILE="inputs/infile.in"

# Check if the binary exists
if [[ ! -f "$BINARY_PATH" ]]; then
    echo "Error: Binary not found at $BINARY_PATH."
    exit 1
fi

# Read the companion file to get the stored dependency hashes
COMPANION_FILE="$BINARY_PATH.hashes"
if [[ ! -f "$COMPANION_FILE" ]]; then
    echo "Error: Companion file not found for binary at $COMPANION_FILE."
    exit 1
fi
STORED_DEPENDENCY_HASHES=$(cat "$COMPANION_FILE")

# Read dependency paths and check if their hashes match
DEPENDENCIES=$(yq eval '.dependencies' "$METADATA_FILE")
DEPENDENCY_COUNT=$(echo "$DEPENDENCIES" | yq eval 'length' -)

# Confirm test details
echo "Test Details:"
echo "-------------"
echo "Test Name: $TEST_NAME"
echo "Test ID: $TEST_ID"
echo "Reason: $TEST_REASON"
echo "Binary Path: $BINARY_PATH"
echo "Input File: $REL_INPUT_FILE"
echo "Log File: $LOG_FILE"
echo "Archive Directory: $ARCHIVE_DIR"
echo ""

# Confirm if the user wants to proceed
read -p "Do you want to run this test? (y/n): " CONFIRM
if [[ ! "$CONFIRM" =~ ^[Yy]$ ]]; then
    echo "Test execution aborted."
    exit 0
fi

# Ask for parallelization method
echo "Select parallel execution mode:"
echo "1) OpenMP (OMP_NUM_THREADS)"
echo "2) MPI (mpirun)"
echo "3) MPI with SLURM (srun)"
read -p "Enter choice (1-3): " PARALLEL_MODE

get_num_cores() {
    AVAILABLE_CORES=$(nproc --all)
    echo "Number of available cores: $AVAILABLE_CORES"
    read -p "Enter the number of cores to use (1-$AVAILABLE_CORES): " NUM_CORES

    if [[ ! "$NUM_CORES" =~ ^[0-9]+$ ]] || (( NUM_CORES < 1 )) || (( NUM_CORES > AVAILABLE_CORES )); then
        echo "Error: Invalid number of cores. Please enter a number between 1 and $AVAILABLE_CORES."
        exit 1
    fi
    echo "$NUM_CORES"
}


get_slurm_walltime() {
    read -p "Enter the number of hours to run the job (1-168): " WALLTIME_HOURS
    #check if the input is in the range
    if [[ ! "$WALLTIME_HOURS" =~ ^[0-9]+$ ]] || (( WALLTIME_HOURS < 1 )) || (( WALLTIME_HOURS > 168 )); then
        echo "Error: Invalid number of hours. Please enter a number between 1 and 168."
        exit 1
    fi
    echo "$WALLTIME_HOURS"
}



# Read the contents of infile to be added as part of each run log
INPUT_FILE_CONTENTS=$(cat "$INPUT_FILE")

# Add separator and input file contents to the log
echo "============================================" >> "$LOG_FILE"
echo "Run started for test: $TEST_NAME" >> "$LOG_FILE"
echo "Input File: $REL_INPUT_FILE" >> "$LOG_FILE"
echo "============================================" >> "$LOG_FILE"
echo "$INPUT_FILE_CONTENTS" >> "$LOG_FILE"
echo "============================================" >> "$LOG_FILE"


# Execute based on chosen parallelization framework
case $PARALLEL_MODE in
    1)
        NUM_CORES=$(get_num_cores)
        export OMP_NUM_THREADS="$NUM_CORES"
        echo "Running test with OMP_NUM_THREADS=$OMP_NUM_THREADS..."
        "$BINARY_PATH" "$REL_INPUT_FILE"
        ;;
    2)
        # Get number of cores for MPI from metadata.yaml
        NUM_CORES=$(yq eval '.Config.cpu_cores' "$METADATA_FILE")
        echo "Running test with MPI using mpirun ($NUM_CORES processes)..."
        mpirun -n "$NUM_CORES" "$BINARY_PATH" "$REL_INPUT_FILE"
        ;;
    3)
        NUM_CORES=$(yq eval '.Config.cpu_cores' "$METADATA_FILE")
        NUM_NODES=$((NUM_CORES / 128))
        NUM_HOURS=$(get_slurm_walltime)
        echo "NUM_CORES: $NUM_CORES"
        echo "NUM_NODES: $NUM_NODES"
        echo "NUM_HOURS: $NUM_HOURS"
        echo "Running test with MPI using SLURM srun ($NUM_CORES processes)..."

        #create the job script
        JOB_SCRIPT="$ARCHIVE_DIR/job_$TEST_ID.job"
        echo "#!/bin/bash" > "$JOB_SCRIPT"
        echo "#SBATCH --ntasks=$NUM_CORES" >> "$JOB_SCRIPT"
        echo "#SBATCH --nodes=$NUM_NODES" >> "$JOB_SCRIPT"
        echo "#SBATCH --time=$NUM_HOURS:00:00" >> "$JOB_SCRIPT"
        echo "#SBATCH --output=$ARCHIVE_DIR/slurm-%j.out" >> "$JOB_SCRIPT"
        echo "#SBATCH --error=$ARCHIVE_DIR/slurm-%j.err" >> "$JOB_SCRIPT"
        echo "# **** Put all #SBATCH directives above this line! ****" >> "$JOB_SCRIPT"
        echo "" >> "$JOB_SCRIPT"
        echo "# **** Actual commands start here ****" >> "$JOB_SCRIPT"
        echo "module purge" >> "$JOB_SCRIPT"
        echo "module load gcc/9.2.0" >> "$JOB_SCRIPT"
        echo "module load openmpi/4.1.1rc1" >> "$JOB_SCRIPT"
        echo "module load netcdf-fortran/4.6.1" >> "$JOB_SCRIPT"
        echo "module load netcdf-c/4.9.0" >> "$JOB_SCRIPT"
        echo "#Run command" >> "$JOB_SCRIPT"
        echo "srun $BINARY_PATH $REL_INPUT_FILE | tee -a outputs/run_test.log" >> "$JOB_SCRIPT"

        #submit the job
        sbatch "$JOB_SCRIPT"

        ;;
    *)
        echo "Error: Invalid selection."
        exit 1
        ;;
esac

# Check exit status
EXIT_STATUS=$?
if [[ $EXIT_STATUS -ne 0 ]]; then
    echo "Error: Test execution failed with exit code $EXIT_STATUS."
    exit $EXIT_STATUS
fi

echo "Test executed successfully."
